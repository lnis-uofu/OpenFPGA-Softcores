#!/usr/bin/env python3

import os, re, time
import numpy as np
from collections import OrderedDict
from utils.parsers.base_parser import BaseParser

class VprReports(object):
    def __init__(self,
                 stats_filename  = "vpr_stat.result",
                 logger_filename = "vpr_stdout.log",
                 searchdir       = os.path.join("run_dir","latest")):
        # Logger file
        self.logger = BaseParser(logger_filename, searchdir, "vpr_logger")
        self._define_logger_parsing_rules()
        self.logger.parse()
        # Result file
        self.stats = BaseParser(stats_filename, searchdir, "vpr_stats")
        self._define_stats_parsing_rules()
        self.stats.parse()

    def __str__(self):
        return f"{self.logger}\n{self.stats}"

    def _define_logger_parsing_rules(self):
        self.logger.add_multiline_regex_rule(
            r'^Pb types usage', r'^$', r'\s+([^ :]+)\s*:\s+(\d+)', "pb_types")
        self.logger.add_regex_rule(r'^FPGA sized to (\d+ x \d+):', "device_layout")
        self.logger.add_regex_rule(r'Fmax:\s+(.+)', "max_frequency")
        self.logger.add_regex_rule(r'Maximum net length:\s+(\d+)', "max_net_length")
        self.logger.add_regex_rule(r'^Average number of bends per net:\s+([^ ]+)', "avg_bends_per_net")
        self.logger.add_regex_rule(r'Maximum \# of bends:\s+(\d+)', "max_bends")
        self.logger.add_regex_rule(r'average wire segments per net:\s+([^ ]+)', "avg_segments_per_net")
        self.logger.add_regex_rule(r'Maximum segments used by a net:\s+(\d+)', "max_segments_per_net")
        # Channel width
        self.logger.add_regex_rule(r'^Best routing .+ (\d+)\.', "channel_width")
        self.logger.add_regex_rule(r'^Circuit successfully routed .+ (\d+)\.', "channel_width")
        self.logger.add_regex_rule(r'^Circuit is (unroutable)', "channel_width")

    def _define_stats_parsing_rules(self):
        self.stats.add_regex_rule(r'^clb_blocks = (\d+)', "clb_blocks")
        self.stats.add_regex_rule(r'^io_blocks = (\d+)', "io_blocks")
        self.stats.add_regex_rule(r'^memory_blocks = (\d+)', "memory_blocks")
        self.stats.add_regex_rule(r'^average_net_length = ([^ ]+)', "avg_net_length")
        self.stats.add_regex_rule(r'^critical_path = ([^ ]+)', "critical_path")
        self.stats.add_regex_rule(r'^total_routing_area = ([^ ]+)', "total_routing_area")
        self.stats.add_regex_rule(r'^total_logic_block_area = ([^ ]+)', "total_logic_block_area")
        self.stats.add_regex_rule(r'^total_wire_length = ([^ ]+)', "total_wire_length")


class VprReportTiming(object):
    """
    Parse a report timing file (generated by VPR) to analyze the top 100
    critical paths. The goal is to group signals together, count signals to
    evaluate wiring congestion of CLB/DSP/BRAM interfaces.
    """

    # Define report file regular expressions
    _reUnitScale        = re.compile(r'# Unit scale: (.+) seconds')
    _rePathNumber       = re.compile(r'#Path (\d+)')
    _reStartpoint       = re.compile(r'Startpoint:\s+([^\s]+)')
    _reEndpoint         = re.compile(r'Endpoint\s*:\s+([^\s]+)')
    _reRequiredTime     = re.compile(r'data required time\s+([^\s]+)')
    _reArrivalTime      = re.compile(r'data arrival time\s+([^\s]+)')
    _reSlackTime        = re.compile(r'slack \(\w+\)\s+([^\s]+)')
    _reStartOfWireTable = re.compile(r'Point\s+Incr\s+Path')
    _reWireInput        = re.compile(r'\$abc.+\$([^\.\$\[\]]+)\.in\[(\d+)\]')
    _reWireOutput       = re.compile(r'\$abc.+\$([^\.\$\[\]]+)\.out\[(\d+)\]')
    _reEndOfWireTable   = re.compile(r'data required time')

    def __init__(self, filename):
        self.filename   = filename
        self.fileinfo   = {}            # store all file information
        self.paths      = []            # list all paths of the files
        self.groups     = OrderedDict() # list all group of paths
        self.stats      = OrderedDict() # store statistics of paths

    def __str__(self):
        """For debbuging purpose: print(object)."""
        tim = []
        for p in self.paths:
            tim.append(f"{p['number']:3}| slack: {p['slack_time']:.3f}, start: {p['startpoint']}, end: {p['endpoint']}, wires: {len(p['wires'])}")
        return '\n'.join(tim)

    def __getitem__(self, idx):
        """Use this class as a list, in order to iterate each path."""
        return self.paths[idx]

    def parse(self, nb_paths=100):
        """Parse the report file using the class regex."""
        with open(self.filename, 'r') as fp:
            path  = dict()
            wires = list()
            token = False
            for line in fp.readlines():
                line = line.rstrip()
                # Unit scale
                m = self._reUnitScale.match(line)
                if m: self.fileinfo.update({'unit_scale' :  m.group(1).strip()})
                # Path number
                m = self._rePathNumber.match(line)
                if m: path['number'] = int(m.group(1))
                # Start point
                m = self._reStartpoint.match(line)
                if m: path['startpoint'] = m.group(1)
                # End point
                m = self._reEndpoint.match(line)
                if m: path['endpoint'] = m.group(1)
                # Required time
                m = self._reRequiredTime.match(line)
                if m: path['required_time'] = float(m.group(1))
                # Arrival time
                m = self._reArrivalTime.match(line)
                if m: path['arrival_time'] = float(m.group(1))
                # Slack time (last item to catch)
                m = self._reSlackTime.match(line)
                if m:
                    path['slack_time'] = float(m.group(1))
                    self.paths.append(path)
                    # if we limit the exploration for a given number of paths
                    if len(self.paths) >= nb_paths:
                        break
                    path = dict()
                # Wire table
                if self._reStartOfWireTable.match(line) and not token:
                    token = True
                if self._reEndOfWireTable.match(line) and token:
                    token = False
                    path['wires'] = list(wires)
                    wires = list()
                # Input wire
                m = self._reWireInput.match(line)
                if m and token:
                    wires.append([f"{m.group(1)}[{m.group(2)}]"])
                # Output wire
                m = self._reWireOutput.match(line)
                if m and token:
                    wires[-1].append(f"{m.group(1)}[{m.group(2)}]")
        # Create group of paths
        for p in self.paths:
            if p['startpoint'] in self.groups:
                self.groups[p['startpoint']]['end_list'].append(p['endpoint'])
                self.groups[p['startpoint']]['total'] += 1
                continue
            self.groups[p['startpoint']] = {
                'end'       : p['endpoint'],
                'end_list'  : [p['endpoint']],
                'total'     : 1,
            }
        # Calculate statistics
        high = self.paths[0]['arrival_time']
        low  = self.paths[-1]['arrival_time']
        self.stats.update({
            'highest_arrival_time'  : high,
            'lowest_arrival_time'   : low,
            'arrival_time_deviation': np.abs(high) - np.abs(low),
        })
        # Get file updated date and time
        self.fileinfo['modified_datetime'] = time.ctime(os.path.getmtime(self.filename))

    def print_groups(self, debug=False):
        for start, count in self.groups.items():
            print(f"{count['total']:3} paths, {start} -> {count['end']}")
            if debug:
                for p in count['end_list'][1:]:
                    print(f"{' '*(12+len(start))}-> {p}")

    def print_stats(self):
        width = 25
        print(f"modified_datetime{' '*(width-17)}: {self.fileinfo['modified_datetime']}")
        print(f"unit_scale{' '*(width-10)}: {self.fileinfo['unit_scale']} seconds")
        for stat, values in self.stats.items():
            print(f"{stat}{' '*(width-len(stat))}: {values:8.4f}")


## Quick and dirty unit test
if __name__ == "__main__":
    import argparse
    from pprint import pprint

    # Parse all arguments
    ap = argparse.ArgumentParser(description=__doc__,
                                 formatter_class=argparse.RawTextHelpFormatter)
    ap.add_argument('report_filename', type=str,
                    help="VPR timing report file to parse")
    ap.add_argument('-d', '--debug', action='store_true',
                    help="print the full content of the path list")
    ap.add_argument('-n', '--nb-paths', metavar='<#-of-paths>', type=int,
                    help="number of paths to display (default: %(default)s)",
                    default=100)
    ap.add_argument('-s', '--stats', action='store_true',
                    help="print only statistics")
    args = ap.parse_args()
    rpt = VprReportTiming(args.report_filename)
    rpt.parse(args.nb_paths)
    if args.debug and not args.stats:
        pprint(rpt.paths)
    # print all paths
    if not args.stats:
        print(f"**********  LIST OF PATHS (TOP: {args.nb_paths})  **********")
        print(rpt)
    print(f"**********  GROUP OF PATHS (TOP: {args.nb_paths})  **********")
    rpt.print_groups(debug=args.debug)
    print("**********  STATISTICS  **********")
    rpt.print_stats()
