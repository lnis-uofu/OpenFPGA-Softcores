#!/usr/bin/env python3

import os, re, time
import numpy as np
from collections import OrderedDict

class Path(list):
    """
    Define the path object to store path properties and manipulate each point
    composing the path like a Python list object.
    """
    def __init__(self, *args, **kwargs):
        # inherit from a list type
        list.__init__(self, *args)
        # path properties
        self.id             = kwargs.get('id', None)
        self.startpoint     = kwargs.get('startpoint', None)
        self.endpoint       = kwargs.get('endpoint', None)
        self.type           = kwargs.get('type', None)
        self.arrival_time   = kwargs.get('arrival_time', None)
        self.required_time  = kwargs.get('required_time', None)
        self.slack_time     = kwargs.get('slack_time', None)


class VprReportTimingParser(object):
    """
    Parse a report timing file (generated by VPR) to analyze the top 100
    critical paths. The goal is to group signals together, count signals to
    evaluate wiring congestion of CLB/DSP/BRAM interfaces.
    """

    ## Define timing report regular expressions
    # File information
    _rcUnitScale        = re.compile(r'# Unit scale: (.+) seconds')
    # Path information
    _rcPathNumber       = re.compile(r'#Path (\d+)')
    _rcStartpoint       = re.compile(r'Startpoint:\s+([^\s]+)')
    _rcEndpoint         = re.compile(r'Endpoint\s*:\s+([^\s]+)')
    _rcPathType         = re.compile(r'Path Type\s*:\s+([^\s]+)')
    _rcArrivalTime      = re.compile(r'data arrival time\s+([\-\d\.]+)')
    _rcRequiredTime     = re.compile(r'data required time\s+([\-\d\.]+)')
    _rcSlackTime        = re.compile(r'slack .*\s+([\-\d\.]+)')
    # For each point in the path list
    _rcPathPoint        = re.compile(r'([^\s]+\[\d+\]) .*\s+([\d\.]+)\s+([\d\.]+)')
    _rStartOfPointTable = r'({}) .*\s+([\d\.]+)\s+([\d\.]+)'
    _rEndOfPointTable   = r'({}) .*\s+([\d\.]+)\s+([\d\.]+)'

    ## Catch path description for a single regex with its associated attribute
    ## and type casting.
    _path_info = [
        # regex, path-attribute, post-processing
        (_rcPathNumber,     'id',               int),
        (_rcStartpoint,     'startpoint',       str),
        (_rcEndpoint,       'endpoint',         str),
        (_rcPathType,       'type',             str),
        (_rcArrivalTime,    'arrival_time',     float),
        (_rcRequiredTime,   'required_time',    float),
        (_rcSlackTime,      'slack_time',       float),
    ]

    def __init__(self, filename, nb_paths=100):
        self.filename   = filename
        self.nb_paths   = nb_paths
        self.fileinfo   = {}            # store all file information
        self.paths      = []            # list all paths of the files
        self.groups     = OrderedDict() # list all group of paths
        self.stats      = OrderedDict() # store statistics of paths
        self.parse()

    def __str__(self):
        """For debbuging purpose: print(object)."""
        tim = []
        for p in self.paths:
            tim.append(f"{p.id:3}| slack: {p.slack_time:.3f}, start: {p.startpoint}, end: {p.endpoint}, points: {len(p)}")
        return '\n'.join(tim)

    def __getitem__(self, idx):
        """Use this class as a list, in order to iterate each path."""
        return self.paths[idx]

    def parse(self):
        """Parse the report file using the class regex."""
        # Get file updated date and time
        self.fileinfo['modified_datetime'] = time.ctime(os.path.getmtime(self.filename))
        # Parse the report timing file
        with open(self.filename, 'r') as fp:
            path  = Path()
            token = False
            for line in fp.readlines():
                line = line.rstrip()
                ## File information
                m = self._rcUnitScale.match(line)
                if m:
                    self.fileinfo['unit_scale'] = m.group(1).strip()
                ## Path information
                for regex, attrib, fmt in self._path_info:
                    m = regex.match(line)
                    if m:
                        setattr(path, attrib, fmt(m.group(1)))
                # end of path and loop breaker
                if self._rcSlackTime.match(line):
                    self.paths.append(path)
                    if path.id >= self.nb_paths:
                        break
                    path = Path()
                ## Point table
                if path.startpoint is None or path.endpoint is None:
                    continue
                # from the startpoint...
                regex = self._rStartOfPointTable.format(re.escape(path.startpoint))
                if re.match(regex, line) and not token:
                    token = True
                # ...for each point...
                m = self._rcPathPoint.match(line)
                if m and token:
                    # add a new point in the path list
                    path.append({
                        'point' : m.group(1),
                        'incr'  : float(m.group(2)),
                        'sum'   : float(m.group(3)),
                    })
                # ...to the endpoint
                regex = self._rEndOfPointTable.format(re.escape(path.endpoint))
                if re.match(regex, line) and token:
                    token = False
        # Create group of paths
        for p in self.paths:
            if p.startpoint in self.groups:
                self.groups[p.startpoint]['end_list'].append(p.endpoint)
                self.groups[p.startpoint]['total'] += 1
                continue
            self.groups[p.startpoint] = {
                'end'       : p.endpoint,
                'end_list'  : [p.endpoint],
                'total'     : 1,
            }
        # Calculate statistics
        if not self.paths:
            return
        high = self.paths[0].arrival_time
        low  = self.paths[-1].arrival_time
        self.stats.update({
            'highest_arrival_time'  : high,
            'lowest_arrival_time'   : low,
            'arrival_time_deviation': np.abs(high) - np.abs(low),
        })

    def print_groups(self, debug=False):
        for start, count in self.groups.items():
            print(f"{count['total']:3} paths, {start} -> {count['end']}")
            if debug:
                for p in count['end_list'][1:]:
                    print(f"{' '*(12+len(start))}-> {p}")

    def print_stats(self):
        width = 25
        if "modified_datetime" in self.fileinfo:
            print(f"modified_datetime{' '*(width-17)}: {self.fileinfo['modified_datetime']}")
        if "unit_scale" in self.fileinfo:
            print(f"unit_scale{' '*(width-10)}: {self.fileinfo['unit_scale']} seconds")
        for stat, values in self.stats.items():
            print(f"{stat}{' '*(width-len(stat))}: {values:8.4f}")


## Quick and dirty unit test
if __name__ == "__main__":
    import argparse
    from pprint import pprint

    # Parse all arguments
    ap = argparse.ArgumentParser(description=__doc__,
                                 formatter_class=argparse.RawTextHelpFormatter)
    ap.add_argument('report_filename', type=str,
                    help="VPR timing report file to parse")
    ap.add_argument('-d', '--debug', action='store_true',
                    help="print the full content of the path list")
    ap.add_argument('-n', '--nb-paths', metavar='<#-of-paths>', type=int,
                    help="number of paths to display (default: %(default)s)",
                    default=100)
    ap.add_argument('-s', '--stats', action='store_true',
                    help="print only statistics")
    args = ap.parse_args()

    rpt = VprReportTimingParser(args.report_filename, args.nb_paths)
    if args.debug and not args.stats:
        pprint(rpt.paths)
    # print all paths
    if not args.stats:
        print(f"**********  LIST OF PATHS (TOP: {args.nb_paths})  **********")
        print(rpt)
    print(f"**********  GROUP OF PATHS (TOP: {args.nb_paths})  **********")
    rpt.print_groups(debug=args.debug)
    print("**********  STATISTICS  **********")
    rpt.print_stats()
